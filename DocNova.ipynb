{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451f8796-249c-4860-a3a8-c76ba08209d2",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2c8502b4-d949-402a-ab65-6cf968cacc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "606bbe09-68fc-4b09-ba9f-48e5670d4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4.1-nano\"\n",
    "db_name = 'vector_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c4c5bab1-95d5-4d17-b303-8b5c5237bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(openai_api_key[:8])\n",
    "else:\n",
    "    print('OpenAI API key not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e63e08-bc78-4290-a49d-b13193b226a3",
   "metadata": {},
   "source": [
    "## Examine the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3c3b13aa-9189-4e55-8041-0acea885c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_path = \"../knowledge-base/**/*.md\"\n",
    "\n",
    "entire_knowledge_base = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f6982f09-156e-49b3-a257-7c3deb973b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total no of files are 76\n",
      "Total characters in knowledge base: 304,434\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob(knowledge_base_path)\n",
    "print(f'The total no of files are {len(filenames)}')\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r',encoding = 'utf-8') as f:\n",
    "        entire_knowledge_base+= f.read()\n",
    "        entire_knowledge_base += '\\n\\n'\n",
    "\n",
    "print(f\"Total characters in knowledge base: {len(entire_knowledge_base):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e8f7f14-638e-4bfd-9012-dfcc34e85a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total no of files are 76\n",
      "Total characters: 304,434\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob(knowledge_base_path)\n",
    "print(f'The total no of files are {len(filenames)}')\n",
    "extra = {}\n",
    "for filename in filenames:\n",
    "    name = Path(filename).stem\n",
    "    with open(filename, 'r',encoding = 'utf-8') as f:\n",
    "        extra[name.lower()] = f.read()\n",
    "all_text_combined = '\\n\\n'.join(extra.values()) + '\\n\\n'\n",
    "\n",
    "print(f\"Total characters: {len(all_text_combined):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10811c7-0c34-409d-8775-bebbb031d97d",
   "metadata": {},
   "source": [
    "## Count the number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "974cc69a-9bdb-4a7b-9b6b-2c2e25be0428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of tokens used are: 63,555\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(MODEL)\n",
    "tokens = encoding.encode(entire_knowledge_base)\n",
    "print(f\"The total number of tokens used are: {len(tokens):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fdd60-ce01-4010-a249-89fff357fe7f",
   "metadata": {},
   "source": [
    "## LangChain Document Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a1c067bd-e4ac-4353-a31c-db7f64df87a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 76 documents\n"
     ]
    }
   ],
   "source": [
    "folders = glob.glob('../knowledge-base/*')\n",
    "\n",
    "documents = []\n",
    "\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob = '**/*.md', loader_cls = TextLoader, loader_kwargs = {'encoding':'utf-8'})\n",
    "    folder_docs = loader.load()\n",
    "\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata['doc_type'] = doc_type\n",
    "        documents.append(doc)\n",
    "        \n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb250d-2dc3-49dd-a049-cc1732487527",
   "metadata": {},
   "source": [
    "## Split each Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f00630b4-d98f-4afc-920a-cb4f56a91241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='### Seamless Integrations\n",
      "Rellm's architecture is designed for effortless integration with existing systems. Whether it's policy management, claims processing, or financial reporting, Rellm connects seamlessly with diverse data sources to create a unified ecosystem.\n",
      "\n",
      "### Risk Assessment Module\n",
      "The comprehensive risk assessment module within Rellm allows insurers to evaluate risk profiles accurately. By leveraging historical data and advanced modeling techniques, Rellm provides a clear picture of potential liabilities and expected outcomes.\n",
      "\n",
      "### Customizable Dashboard\n",
      "Rellm features a customizable dashboard that presents key metrics and performance indicators in an intuitive interface. Users can tailor their view to focus on what matters most to their business, enhancing user experience and productivity.' metadata={'source': '../knowledge-base/products/Rellm.md', 'doc_type': 'products'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap= 200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e54c8b-d898-4e8b-b243-fa69dd4887a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
